2025-08-13 08:21:17,149 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:23:35,478 - INFO - No existing output found. Starting fresh.
2025-08-13 08:23:35,520 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\img
2025-08-13 08:23:35,557 - INFO - Found 0 images.
2025-08-13 08:23:35,558 - WARNING - No supported images found. Exiting.
2025-08-13 08:24:22,146 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:26:42,986 - INFO - No existing output found. Starting fresh.
2025-08-13 08:26:43,034 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 08:26:43,083 - INFO - Found 100 images.
2025-08-13 08:26:43,083 - INFO - --- Processing Page 1/100: UBOBU_UBO8306198_277667_0001.jpg ---
2025-08-13 08:26:46,519 - ERROR - Critical error on page 1: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:46,647 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:46,647 - INFO - --- Processing Page 2/100: UBOBU_UBO8306198_277667_0002.jpg ---
2025-08-13 08:26:46,823 - ERROR - Critical error on page 2: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:46,823 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:46,823 - INFO - --- Processing Page 3/100: UBOBU_UBO8306198_277667_0003.jpg ---
2025-08-13 08:26:47,007 - ERROR - Critical error on page 3: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,007 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,007 - INFO - --- Processing Page 4/100: UBOBU_UBO8306198_277667_0004.jpg ---
2025-08-13 08:26:47,202 - ERROR - Critical error on page 4: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,202 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,202 - INFO - --- Processing Page 5/100: UBOBU_UBO8306198_277667_0005.jpg ---
2025-08-13 08:26:47,428 - ERROR - Critical error on page 5: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,434 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,434 - INFO - --- Processing Page 6/100: UBOBU_UBO8306198_277667_0006.jpg ---
2025-08-13 08:26:47,631 - ERROR - Critical error on page 6: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,632 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,632 - INFO - --- Processing Page 7/100: UBOBU_UBO8306198_277667_0007.jpg ---
2025-08-13 08:26:47,805 - ERROR - Critical error on page 7: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,809 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,809 - INFO - --- Processing Page 8/100: UBOBU_UBO8306198_277667_0008.jpg ---
2025-08-13 08:26:47,971 - ERROR - Critical error on page 8: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:47,986 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:47,986 - INFO - --- Processing Page 9/100: UBOBU_UBO8306198_277667_0009.jpg ---
2025-08-13 08:26:48,190 - ERROR - Critical error on page 9: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:48,197 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:48,197 - INFO - --- Processing Page 10/100: UBOBU_UBO8306198_277667_0010.jpg ---
2025-08-13 08:26:48,546 - ERROR - Critical error on page 10: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:48,553 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:48,553 - INFO - --- Processing Page 11/100: UBOBU_UBO8306198_277667_0011.jpg ---
2025-08-13 08:26:48,869 - ERROR - Critical error on page 11: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:48,871 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:48,871 - INFO - --- Processing Page 12/100: UBOBU_UBO8306198_277667_0012.jpg ---
2025-08-13 08:26:49,190 - ERROR - Critical error on page 12: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:49,196 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:49,196 - INFO - --- Processing Page 13/100: UBOBU_UBO8306198_277667_0013.jpg ---
2025-08-13 08:26:49,449 - ERROR - Critical error on page 13: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:49,449 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:49,449 - INFO - --- Processing Page 14/100: UBOBU_UBO8306198_277667_0014.jpg ---
2025-08-13 08:26:49,691 - ERROR - Critical error on page 14: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:49,697 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:49,697 - INFO - --- Processing Page 15/100: UBOBU_UBO8306198_277667_0015.jpg ---
2025-08-13 08:26:49,948 - ERROR - Critical error on page 15: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:49,963 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:49,963 - INFO - --- Processing Page 16/100: UBOBU_UBO8306198_277667_0016.jpg ---
2025-08-13 08:26:50,245 - ERROR - Critical error on page 16: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:50,247 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:50,247 - INFO - --- Processing Page 17/100: UBOBU_UBO8306198_277667_0017.jpg ---
2025-08-13 08:26:50,517 - ERROR - Critical error on page 17: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:50,525 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:50,525 - INFO - --- Processing Page 18/100: UBOBU_UBO8306198_277667_0018.jpg ---
2025-08-13 08:26:50,802 - ERROR - Critical error on page 18: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:50,812 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:50,812 - INFO - --- Processing Page 19/100: UBOBU_UBO8306198_277667_0019.jpg ---
2025-08-13 08:26:51,104 - ERROR - Critical error on page 19: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:51,111 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:51,111 - INFO - --- Processing Page 20/100: UBOBU_UBO8306198_277667_0020.jpg ---
2025-08-13 08:26:51,402 - ERROR - Critical error on page 20: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:51,409 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:51,409 - INFO - --- Processing Page 21/100: UBOBU_UBO8306198_277667_0021.jpg ---
2025-08-13 08:26:51,694 - ERROR - Critical error on page 21: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:51,696 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:51,696 - INFO - --- Processing Page 22/100: UBOBU_UBO8306198_277667_0022.jpg ---
2025-08-13 08:26:51,963 - ERROR - Critical error on page 22: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:51,964 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:51,964 - INFO - --- Processing Page 23/100: UBOBU_UBO8306198_277667_0023.jpg ---
2025-08-13 08:26:52,198 - ERROR - Critical error on page 23: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:52,200 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:52,200 - INFO - --- Processing Page 24/100: UBOBU_UBO8306198_277667_0024.jpg ---
2025-08-13 08:26:52,420 - ERROR - Critical error on page 24: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:52,437 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:52,439 - INFO - --- Processing Page 25/100: UBOBU_UBO8306198_277667_0025.jpg ---
2025-08-13 08:26:52,696 - ERROR - Critical error on page 25: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:52,701 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:52,702 - INFO - --- Processing Page 26/100: UBOBU_UBO8306198_277667_0026.jpg ---
2025-08-13 08:26:52,936 - ERROR - Critical error on page 26: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:52,946 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:52,946 - INFO - --- Processing Page 27/100: UBOBU_UBO8306198_277667_0027.jpg ---
2025-08-13 08:26:53,087 - ERROR - Critical error on page 27: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,095 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,095 - INFO - --- Processing Page 28/100: UBOBU_UBO8306198_277667_0028.jpg ---
2025-08-13 08:26:53,325 - ERROR - Critical error on page 28: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,332 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,333 - INFO - --- Processing Page 29/100: UBOBU_UBO8306198_277667_0029.jpg ---
2025-08-13 08:26:53,506 - ERROR - Critical error on page 29: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,510 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,510 - INFO - --- Processing Page 30/100: UBOBU_UBO8306198_277667_0030.jpg ---
2025-08-13 08:26:53,640 - ERROR - Critical error on page 30: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,648 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,648 - INFO - --- Processing Page 31/100: UBOBU_UBO8306198_277667_0031.jpg ---
2025-08-13 08:26:53,801 - ERROR - Critical error on page 31: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,804 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,804 - INFO - --- Processing Page 32/100: UBOBU_UBO8306198_277667_0032.jpg ---
2025-08-13 08:26:53,947 - ERROR - Critical error on page 32: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:53,951 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:53,951 - INFO - --- Processing Page 33/100: UBOBU_UBO8306198_277667_0033.jpg ---
2025-08-13 08:26:54,096 - ERROR - Critical error on page 33: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,096 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,096 - INFO - --- Processing Page 34/100: UBOBU_UBO8306198_277667_0034.jpg ---
2025-08-13 08:26:54,224 - ERROR - Critical error on page 34: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,239 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,239 - INFO - --- Processing Page 35/100: UBOBU_UBO8306198_277667_0035.jpg ---
2025-08-13 08:26:54,374 - ERROR - Critical error on page 35: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,374 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,374 - INFO - --- Processing Page 36/100: UBOBU_UBO8306198_277667_0036.jpg ---
2025-08-13 08:26:54,523 - ERROR - Critical error on page 36: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,535 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,535 - INFO - --- Processing Page 37/100: UBOBU_UBO8306198_277667_0037.jpg ---
2025-08-13 08:26:54,664 - ERROR - Critical error on page 37: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,670 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,670 - INFO - --- Processing Page 38/100: UBOBU_UBO8306198_277667_0038.jpg ---
2025-08-13 08:26:54,803 - ERROR - Critical error on page 38: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,806 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,807 - INFO - --- Processing Page 39/100: UBOBU_UBO8306198_277667_0039.jpg ---
2025-08-13 08:26:54,938 - ERROR - Critical error on page 39: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:54,938 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:54,938 - INFO - --- Processing Page 40/100: UBOBU_UBO8306198_277667_0040.jpg ---
2025-08-13 08:26:55,111 - ERROR - Critical error on page 40: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,115 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,115 - INFO - --- Processing Page 41/100: UBOBU_UBO8306198_277667_0041.jpg ---
2025-08-13 08:26:55,255 - ERROR - Critical error on page 41: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,257 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,257 - INFO - --- Processing Page 42/100: UBOBU_UBO8306198_277667_0042.jpg ---
2025-08-13 08:26:55,388 - ERROR - Critical error on page 42: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,398 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,398 - INFO - --- Processing Page 43/100: UBOBU_UBO8306198_277667_0043.jpg ---
2025-08-13 08:26:55,535 - ERROR - Critical error on page 43: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,540 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,540 - INFO - --- Processing Page 44/100: UBOBU_UBO8306198_277667_0044.jpg ---
2025-08-13 08:26:55,682 - ERROR - Critical error on page 44: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,687 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,687 - INFO - --- Processing Page 45/100: UBOBU_UBO8306198_277667_0045.jpg ---
2025-08-13 08:26:55,841 - ERROR - Critical error on page 45: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:55,841 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:55,841 - INFO - --- Processing Page 46/100: UBOBU_UBO8306198_277667_0046.jpg ---
2025-08-13 08:26:56,046 - ERROR - Critical error on page 46: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,049 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,049 - INFO - --- Processing Page 47/100: UBOBU_UBO8306198_277667_0047.jpg ---
2025-08-13 08:26:56,205 - ERROR - Critical error on page 47: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,212 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,213 - INFO - --- Processing Page 48/100: UBOBU_UBO8306198_277667_0048.jpg ---
2025-08-13 08:26:56,339 - ERROR - Critical error on page 48: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,352 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,352 - INFO - --- Processing Page 49/100: UBOBU_UBO8306198_277667_0049.jpg ---
2025-08-13 08:26:56,491 - ERROR - Critical error on page 49: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,494 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,494 - INFO - --- Processing Page 50/100: UBOBU_UBO8306198_277667_0050.jpg ---
2025-08-13 08:26:56,625 - ERROR - Critical error on page 50: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,628 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,629 - INFO - --- Processing Page 51/100: UBOBU_UBO8306198_277667_0051.jpg ---
2025-08-13 08:26:56,769 - ERROR - Critical error on page 51: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,781 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,781 - INFO - --- Processing Page 52/100: UBOBU_UBO8306198_277667_0052.jpg ---
2025-08-13 08:26:56,954 - ERROR - Critical error on page 52: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:56,954 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:56,954 - INFO - --- Processing Page 53/100: UBOBU_UBO8306198_277667_0053.jpg ---
2025-08-13 08:26:57,107 - ERROR - Critical error on page 53: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,107 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,107 - INFO - --- Processing Page 54/100: UBOBU_UBO8306198_277667_0054.jpg ---
2025-08-13 08:26:57,260 - ERROR - Critical error on page 54: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,264 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,264 - INFO - --- Processing Page 55/100: UBOBU_UBO8306198_277667_0055.jpg ---
2025-08-13 08:26:57,403 - ERROR - Critical error on page 55: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,403 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,403 - INFO - --- Processing Page 56/100: UBOBU_UBO8306198_277667_0056.jpg ---
2025-08-13 08:26:57,560 - ERROR - Critical error on page 56: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,564 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,564 - INFO - --- Processing Page 57/100: UBOBU_UBO8306198_277667_0057.jpg ---
2025-08-13 08:26:57,697 - ERROR - Critical error on page 57: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,704 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,704 - INFO - --- Processing Page 58/100: UBOBU_UBO8306198_277667_0058.jpg ---
2025-08-13 08:26:57,839 - ERROR - Critical error on page 58: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,844 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,845 - INFO - --- Processing Page 59/100: UBOBU_UBO8306198_277667_0059.jpg ---
2025-08-13 08:26:57,976 - ERROR - Critical error on page 59: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:57,976 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:57,976 - INFO - --- Processing Page 60/100: UBOBU_UBO8306198_277667_0060.jpg ---
2025-08-13 08:26:58,104 - ERROR - Critical error on page 60: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,120 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,120 - INFO - --- Processing Page 61/100: UBOBU_UBO8306198_277667_0061.jpg ---
2025-08-13 08:26:58,270 - ERROR - Critical error on page 61: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,270 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,270 - INFO - --- Processing Page 62/100: UBOBU_UBO8306198_277667_0062.jpg ---
2025-08-13 08:26:58,482 - ERROR - Critical error on page 62: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,485 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,485 - INFO - --- Processing Page 63/100: UBOBU_UBO8306198_277667_0063.jpg ---
2025-08-13 08:26:58,683 - ERROR - Critical error on page 63: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,683 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,683 - INFO - --- Processing Page 64/100: UBOBU_UBO8306198_277667_0064.jpg ---
2025-08-13 08:26:58,821 - ERROR - Critical error on page 64: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,821 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,821 - INFO - --- Processing Page 65/100: UBOBU_UBO8306198_277667_0065.jpg ---
2025-08-13 08:26:58,971 - ERROR - Critical error on page 65: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:58,974 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:58,974 - INFO - --- Processing Page 66/100: UBOBU_UBO8306198_277667_0066.jpg ---
2025-08-13 08:26:59,104 - ERROR - Critical error on page 66: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,104 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,104 - INFO - --- Processing Page 67/100: UBOBU_UBO8306198_277667_0067.jpg ---
2025-08-13 08:26:59,234 - ERROR - Critical error on page 67: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,239 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,239 - INFO - --- Processing Page 68/100: UBOBU_UBO8306198_277667_0068.jpg ---
2025-08-13 08:26:59,355 - ERROR - Critical error on page 68: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,371 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,371 - INFO - --- Processing Page 69/100: UBOBU_UBO8306198_277667_0069.jpg ---
2025-08-13 08:26:59,506 - ERROR - Critical error on page 69: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,523 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,523 - INFO - --- Processing Page 70/100: UBOBU_UBO8306198_277667_0070.jpg ---
2025-08-13 08:26:59,671 - ERROR - Critical error on page 70: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,676 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,676 - INFO - --- Processing Page 71/100: UBOBU_UBO8306198_277667_0071.jpg ---
2025-08-13 08:26:59,825 - ERROR - Critical error on page 71: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,831 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,833 - INFO - --- Processing Page 72/100: UBOBU_UBO8306198_277667_0072.jpg ---
2025-08-13 08:26:59,963 - ERROR - Critical error on page 72: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:26:59,976 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:26:59,976 - INFO - --- Processing Page 73/100: UBOBU_UBO8306198_277667_0073.jpg ---
2025-08-13 08:27:00,151 - ERROR - Critical error on page 73: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,151 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,151 - INFO - --- Processing Page 74/100: UBOBU_UBO8306198_277667_0074.jpg ---
2025-08-13 08:27:00,290 - ERROR - Critical error on page 74: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,290 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,290 - INFO - --- Processing Page 75/100: UBOBU_UBO8306198_277667_0075.jpg ---
2025-08-13 08:27:00,440 - ERROR - Critical error on page 75: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,440 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,440 - INFO - --- Processing Page 76/100: UBOBU_UBO8306198_277667_0076.jpg ---
2025-08-13 08:27:00,590 - ERROR - Critical error on page 76: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,606 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,606 - INFO - --- Processing Page 77/100: UBOBU_UBO8306198_277667_0077.jpg ---
2025-08-13 08:27:00,757 - ERROR - Critical error on page 77: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,757 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,757 - INFO - --- Processing Page 78/100: UBOBU_UBO8306198_277667_0078.jpg ---
2025-08-13 08:27:00,906 - ERROR - Critical error on page 78: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:00,911 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:00,911 - INFO - --- Processing Page 79/100: UBOBU_UBO8306198_277667_0079.jpg ---
2025-08-13 08:27:01,073 - ERROR - Critical error on page 79: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,077 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,077 - INFO - --- Processing Page 80/100: UBOBU_UBO8306198_277667_0080.jpg ---
2025-08-13 08:27:01,217 - ERROR - Critical error on page 80: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,223 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,223 - INFO - --- Processing Page 81/100: UBOBU_UBO8306198_277667_0081.jpg ---
2025-08-13 08:27:01,354 - ERROR - Critical error on page 81: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,370 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,370 - INFO - --- Processing Page 82/100: UBOBU_UBO8306198_277667_0082.jpg ---
2025-08-13 08:27:01,504 - ERROR - Critical error on page 82: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,507 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,507 - INFO - --- Processing Page 83/100: UBOBU_UBO8306198_277667_0083.jpg ---
2025-08-13 08:27:01,654 - ERROR - Critical error on page 83: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,654 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,654 - INFO - --- Processing Page 84/100: UBOBU_UBO8306198_277667_0084.jpg ---
2025-08-13 08:27:01,805 - ERROR - Critical error on page 84: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,810 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,810 - INFO - --- Processing Page 85/100: UBOBU_UBO8306198_277667_0085.jpg ---
2025-08-13 08:27:01,941 - ERROR - Critical error on page 85: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:01,956 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:01,956 - INFO - --- Processing Page 86/100: UBOBU_UBO8306198_277667_0086.jpg ---
2025-08-13 08:27:02,090 - ERROR - Critical error on page 86: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,090 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,090 - INFO - --- Processing Page 87/100: UBOBU_UBO8306198_277667_0087.jpg ---
2025-08-13 08:27:02,255 - ERROR - Critical error on page 87: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,259 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,260 - INFO - --- Processing Page 88/100: UBOBU_UBO8306198_277667_0088.jpg ---
2025-08-13 08:27:02,395 - ERROR - Critical error on page 88: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,395 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,395 - INFO - --- Processing Page 89/100: UBOBU_UBO8306198_277667_0089.jpg ---
2025-08-13 08:27:02,523 - ERROR - Critical error on page 89: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,523 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,523 - INFO - --- Processing Page 90/100: UBOBU_UBO8306198_277667_0090.jpg ---
2025-08-13 08:27:02,734 - ERROR - Critical error on page 90: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,742 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,743 - INFO - --- Processing Page 91/100: UBOBU_UBO8306198_277667_0091.jpg ---
2025-08-13 08:27:02,923 - ERROR - Critical error on page 91: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:02,931 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:02,931 - INFO - --- Processing Page 92/100: UBOBU_UBO8306198_277667_0092.jpg ---
2025-08-13 08:27:03,071 - ERROR - Critical error on page 92: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,080 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,080 - INFO - --- Processing Page 93/100: UBOBU_UBO8306198_277667_0093.jpg ---
2025-08-13 08:27:03,224 - ERROR - Critical error on page 93: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,227 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,227 - INFO - --- Processing Page 94/100: UBOBU_UBO8306198_277667_0094.jpg ---
2025-08-13 08:27:03,364 - ERROR - Critical error on page 94: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,370 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,371 - INFO - --- Processing Page 95/100: UBOBU_UBO8306198_277667_0095.jpg ---
2025-08-13 08:27:03,490 - ERROR - Critical error on page 95: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,505 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,505 - INFO - --- Processing Page 96/100: UBOBU_UBO8306198_277667_0096.jpg ---
2025-08-13 08:27:03,671 - ERROR - Critical error on page 96: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,673 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,673 - INFO - --- Processing Page 97/100: UBOBU_UBO8306198_277667_0097.jpg ---
2025-08-13 08:27:03,810 - ERROR - Critical error on page 97: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,810 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,816 - INFO - --- Processing Page 98/100: UBOBU_UBO8306198_277667_0098.jpg ---
2025-08-13 08:27:03,964 - ERROR - Critical error on page 98: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:03,974 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:03,974 - INFO - --- Processing Page 99/100: UBOBU_UBO8306198_277667_0099.jpg ---
2025-08-13 08:27:04,110 - ERROR - Critical error on page 99: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:04,110 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:04,110 - INFO - --- Processing Page 100/100: UBOBU_UBO8306198_277667_0100.jpg ---
2025-08-13 08:27:04,256 - ERROR - Critical error on page 100: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 269, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 187, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 08:27:04,263 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:04,263 - INFO - ================================================================================
2025-08-13 08:27:04,263 - INFO - Processing complete.
2025-08-13 08:27:04,263 - INFO - All results saved to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:27:04,264 - INFO - ================================================================================
2025-08-13 08:29:46,331 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:32:21,660 - INFO - Checking for existing output file: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:32:23,843 - INFO - Loaded 100 existing records.
2025-08-13 08:32:23,843 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 08:32:23,872 - INFO - Found 100 images.
2025-08-13 08:32:23,872 - INFO - Page 1 (UBOBU_UBO8306198_277667_0001.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 2 (UBOBU_UBO8306198_277667_0002.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 3 (UBOBU_UBO8306198_277667_0003.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 4 (UBOBU_UBO8306198_277667_0004.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 5 (UBOBU_UBO8306198_277667_0005.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 6 (UBOBU_UBO8306198_277667_0006.jpg) already processed. Skipping.
2025-08-13 08:32:23,872 - INFO - Page 7 (UBOBU_UBO8306198_277667_0007.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 8 (UBOBU_UBO8306198_277667_0008.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 9 (UBOBU_UBO8306198_277667_0009.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 10 (UBOBU_UBO8306198_277667_0010.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 11 (UBOBU_UBO8306198_277667_0011.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 12 (UBOBU_UBO8306198_277667_0012.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 13 (UBOBU_UBO8306198_277667_0013.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 14 (UBOBU_UBO8306198_277667_0014.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 15 (UBOBU_UBO8306198_277667_0015.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 16 (UBOBU_UBO8306198_277667_0016.jpg) already processed. Skipping.
2025-08-13 08:32:23,876 - INFO - Page 17 (UBOBU_UBO8306198_277667_0017.jpg) already processed. Skipping.
2025-08-13 08:32:23,877 - INFO - Page 18 (UBOBU_UBO8306198_277667_0018.jpg) already processed. Skipping.
2025-08-13 08:32:23,877 - INFO - Page 19 (UBOBU_UBO8306198_277667_0019.jpg) already processed. Skipping.
2025-08-13 08:32:23,877 - INFO - Page 20 (UBOBU_UBO8306198_277667_0020.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 21 (UBOBU_UBO8306198_277667_0021.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 22 (UBOBU_UBO8306198_277667_0022.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 23 (UBOBU_UBO8306198_277667_0023.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 24 (UBOBU_UBO8306198_277667_0024.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 25 (UBOBU_UBO8306198_277667_0025.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 26 (UBOBU_UBO8306198_277667_0026.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 27 (UBOBU_UBO8306198_277667_0027.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 28 (UBOBU_UBO8306198_277667_0028.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 29 (UBOBU_UBO8306198_277667_0029.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 30 (UBOBU_UBO8306198_277667_0030.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 31 (UBOBU_UBO8306198_277667_0031.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 32 (UBOBU_UBO8306198_277667_0032.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 33 (UBOBU_UBO8306198_277667_0033.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 34 (UBOBU_UBO8306198_277667_0034.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 35 (UBOBU_UBO8306198_277667_0035.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 36 (UBOBU_UBO8306198_277667_0036.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 37 (UBOBU_UBO8306198_277667_0037.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 38 (UBOBU_UBO8306198_277667_0038.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 39 (UBOBU_UBO8306198_277667_0039.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 40 (UBOBU_UBO8306198_277667_0040.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 41 (UBOBU_UBO8306198_277667_0041.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 42 (UBOBU_UBO8306198_277667_0042.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 43 (UBOBU_UBO8306198_277667_0043.jpg) already processed. Skipping.
2025-08-13 08:32:23,878 - INFO - Page 44 (UBOBU_UBO8306198_277667_0044.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 45 (UBOBU_UBO8306198_277667_0045.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 46 (UBOBU_UBO8306198_277667_0046.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 47 (UBOBU_UBO8306198_277667_0047.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 48 (UBOBU_UBO8306198_277667_0048.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 49 (UBOBU_UBO8306198_277667_0049.jpg) already processed. Skipping.
2025-08-13 08:32:23,893 - INFO - Page 50 (UBOBU_UBO8306198_277667_0050.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 51 (UBOBU_UBO8306198_277667_0051.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 52 (UBOBU_UBO8306198_277667_0052.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 53 (UBOBU_UBO8306198_277667_0053.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 54 (UBOBU_UBO8306198_277667_0054.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 55 (UBOBU_UBO8306198_277667_0055.jpg) already processed. Skipping.
2025-08-13 08:32:23,894 - INFO - Page 56 (UBOBU_UBO8306198_277667_0056.jpg) already processed. Skipping.
2025-08-13 08:32:23,896 - INFO - Page 57 (UBOBU_UBO8306198_277667_0057.jpg) already processed. Skipping.
2025-08-13 08:32:23,896 - INFO - Page 58 (UBOBU_UBO8306198_277667_0058.jpg) already processed. Skipping.
2025-08-13 08:32:23,896 - INFO - Page 59 (UBOBU_UBO8306198_277667_0059.jpg) already processed. Skipping.
2025-08-13 08:32:23,896 - INFO - Page 60 (UBOBU_UBO8306198_277667_0060.jpg) already processed. Skipping.
2025-08-13 08:32:23,896 - INFO - Page 61 (UBOBU_UBO8306198_277667_0061.jpg) already processed. Skipping.
2025-08-13 08:32:23,897 - INFO - Page 62 (UBOBU_UBO8306198_277667_0062.jpg) already processed. Skipping.
2025-08-13 08:32:23,897 - INFO - Page 63 (UBOBU_UBO8306198_277667_0063.jpg) already processed. Skipping.
2025-08-13 08:32:23,897 - INFO - Page 64 (UBOBU_UBO8306198_277667_0064.jpg) already processed. Skipping.
2025-08-13 08:32:23,897 - INFO - Page 65 (UBOBU_UBO8306198_277667_0065.jpg) already processed. Skipping.
2025-08-13 08:32:23,897 - INFO - Page 66 (UBOBU_UBO8306198_277667_0066.jpg) already processed. Skipping.
2025-08-13 08:32:23,898 - INFO - Page 67 (UBOBU_UBO8306198_277667_0067.jpg) already processed. Skipping.
2025-08-13 08:32:23,898 - INFO - Page 68 (UBOBU_UBO8306198_277667_0068.jpg) already processed. Skipping.
2025-08-13 08:32:23,898 - INFO - Page 69 (UBOBU_UBO8306198_277667_0069.jpg) already processed. Skipping.
2025-08-13 08:32:23,898 - INFO - Page 70 (UBOBU_UBO8306198_277667_0070.jpg) already processed. Skipping.
2025-08-13 08:32:23,900 - INFO - Page 71 (UBOBU_UBO8306198_277667_0071.jpg) already processed. Skipping.
2025-08-13 08:32:23,900 - INFO - Page 72 (UBOBU_UBO8306198_277667_0072.jpg) already processed. Skipping.
2025-08-13 08:32:23,900 - INFO - Page 73 (UBOBU_UBO8306198_277667_0073.jpg) already processed. Skipping.
2025-08-13 08:32:23,900 - INFO - Page 74 (UBOBU_UBO8306198_277667_0074.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 75 (UBOBU_UBO8306198_277667_0075.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 76 (UBOBU_UBO8306198_277667_0076.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 77 (UBOBU_UBO8306198_277667_0077.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 78 (UBOBU_UBO8306198_277667_0078.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 79 (UBOBU_UBO8306198_277667_0079.jpg) already processed. Skipping.
2025-08-13 08:32:23,901 - INFO - Page 80 (UBOBU_UBO8306198_277667_0080.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 81 (UBOBU_UBO8306198_277667_0081.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 82 (UBOBU_UBO8306198_277667_0082.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 83 (UBOBU_UBO8306198_277667_0083.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 84 (UBOBU_UBO8306198_277667_0084.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 85 (UBOBU_UBO8306198_277667_0085.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 86 (UBOBU_UBO8306198_277667_0086.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 87 (UBOBU_UBO8306198_277667_0087.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 88 (UBOBU_UBO8306198_277667_0088.jpg) already processed. Skipping.
2025-08-13 08:32:23,902 - INFO - Page 89 (UBOBU_UBO8306198_277667_0089.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 90 (UBOBU_UBO8306198_277667_0090.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 91 (UBOBU_UBO8306198_277667_0091.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 92 (UBOBU_UBO8306198_277667_0092.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 93 (UBOBU_UBO8306198_277667_0093.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 94 (UBOBU_UBO8306198_277667_0094.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 95 (UBOBU_UBO8306198_277667_0095.jpg) already processed. Skipping.
2025-08-13 08:32:23,903 - INFO - Page 96 (UBOBU_UBO8306198_277667_0096.jpg) already processed. Skipping.
2025-08-13 08:32:23,905 - INFO - Page 97 (UBOBU_UBO8306198_277667_0097.jpg) already processed. Skipping.
2025-08-13 08:32:23,905 - INFO - Page 98 (UBOBU_UBO8306198_277667_0098.jpg) already processed. Skipping.
2025-08-13 08:32:23,905 - INFO - Page 99 (UBOBU_UBO8306198_277667_0099.jpg) already processed. Skipping.
2025-08-13 08:32:23,905 - INFO - Page 100 (UBOBU_UBO8306198_277667_0100.jpg) already processed. Skipping.
2025-08-13 08:32:23,905 - INFO - ================================================================================
2025-08-13 08:32:23,905 - INFO - Processing complete.
2025-08-13 08:32:23,905 - INFO - All results saved to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:32:23,905 - INFO - ================================================================================
2025-08-13 08:40:49,237 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:43:32,093 - INFO - Starting fresh run: all images will be processed.
2025-08-13 08:43:32,112 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 08:43:32,180 - INFO - Found 100 images.
2025-08-13 08:43:32,182 - INFO - --- Processing Page 1/100: UBOBU_UBO8306198_277667_0001.jpg ---
2025-08-13 08:44:04,757 - ERROR - Critical error on page 1: Image features and image tokens do not match: tokens: 0, features 18677760
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 255, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 199, in call_vision_model
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 18677760
2025-08-13 08:44:04,952 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:44:04,952 - INFO - --- Processing Page 2/100: UBOBU_UBO8306198_277667_0002.jpg ---
2025-08-13 08:46:38,108 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:49:01,604 - INFO - Starting fresh run: all images will be processed.
2025-08-13 08:49:01,764 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 08:49:01,837 - INFO - Found 100 images.
2025-08-13 08:49:01,837 - INFO - --- Processing Page 1/100: UBOBU_UBO8306198_277667_0001.jpg ---
2025-08-13 08:49:03,097 - ERROR - Critical error on page 1: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:03,205 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:03,205 - INFO - --- Processing Page 2/100: UBOBU_UBO8306198_277667_0002.jpg ---
2025-08-13 08:49:03,352 - ERROR - Critical error on page 2: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:03,358 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:03,358 - INFO - --- Processing Page 3/100: UBOBU_UBO8306198_277667_0003.jpg ---
2025-08-13 08:49:03,596 - ERROR - Critical error on page 3: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:03,606 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:03,607 - INFO - --- Processing Page 4/100: UBOBU_UBO8306198_277667_0004.jpg ---
2025-08-13 08:49:03,766 - ERROR - Critical error on page 4: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:03,777 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:03,777 - INFO - --- Processing Page 5/100: UBOBU_UBO8306198_277667_0005.jpg ---
2025-08-13 08:49:03,963 - ERROR - Critical error on page 5: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:03,967 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:03,967 - INFO - --- Processing Page 6/100: UBOBU_UBO8306198_277667_0006.jpg ---
2025-08-13 08:49:04,163 - ERROR - Critical error on page 6: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:04,179 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:04,179 - INFO - --- Processing Page 7/100: UBOBU_UBO8306198_277667_0007.jpg ---
2025-08-13 08:49:04,378 - ERROR - Critical error on page 7: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:04,378 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:04,378 - INFO - --- Processing Page 8/100: UBOBU_UBO8306198_277667_0008.jpg ---
2025-08-13 08:49:04,563 - ERROR - Critical error on page 8: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:04,563 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:04,563 - INFO - --- Processing Page 9/100: UBOBU_UBO8306198_277667_0009.jpg ---
2025-08-13 08:49:04,776 - ERROR - Critical error on page 9: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:04,776 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:04,776 - INFO - --- Processing Page 10/100: UBOBU_UBO8306198_277667_0010.jpg ---
2025-08-13 08:49:05,011 - ERROR - Critical error on page 10: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,011 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,011 - INFO - --- Processing Page 11/100: UBOBU_UBO8306198_277667_0011.jpg ---
2025-08-13 08:49:05,167 - ERROR - Critical error on page 11: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,167 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,167 - INFO - --- Processing Page 12/100: UBOBU_UBO8306198_277667_0012.jpg ---
2025-08-13 08:49:05,347 - ERROR - Critical error on page 12: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,347 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,347 - INFO - --- Processing Page 13/100: UBOBU_UBO8306198_277667_0013.jpg ---
2025-08-13 08:49:05,546 - ERROR - Critical error on page 13: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,565 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,565 - INFO - --- Processing Page 14/100: UBOBU_UBO8306198_277667_0014.jpg ---
2025-08-13 08:49:05,803 - ERROR - Critical error on page 14: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,807 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,807 - INFO - --- Processing Page 15/100: UBOBU_UBO8306198_277667_0015.jpg ---
2025-08-13 08:49:05,995 - ERROR - Critical error on page 15: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:05,995 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:05,995 - INFO - --- Processing Page 16/100: UBOBU_UBO8306198_277667_0016.jpg ---
2025-08-13 08:49:06,237 - ERROR - Critical error on page 16: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,239 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,239 - INFO - --- Processing Page 17/100: UBOBU_UBO8306198_277667_0017.jpg ---
2025-08-13 08:49:06,429 - ERROR - Critical error on page 17: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,446 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,446 - INFO - --- Processing Page 18/100: UBOBU_UBO8306198_277667_0018.jpg ---
2025-08-13 08:49:06,565 - ERROR - Critical error on page 18: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,565 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,565 - INFO - --- Processing Page 19/100: UBOBU_UBO8306198_277667_0019.jpg ---
2025-08-13 08:49:06,699 - ERROR - Critical error on page 19: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,699 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,699 - INFO - --- Processing Page 20/100: UBOBU_UBO8306198_277667_0020.jpg ---
2025-08-13 08:49:06,848 - ERROR - Critical error on page 20: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,848 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,848 - INFO - --- Processing Page 21/100: UBOBU_UBO8306198_277667_0021.jpg ---
2025-08-13 08:49:06,981 - ERROR - Critical error on page 21: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:06,997 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:06,997 - INFO - --- Processing Page 22/100: UBOBU_UBO8306198_277667_0022.jpg ---
2025-08-13 08:49:07,136 - ERROR - Critical error on page 22: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:07,136 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:07,136 - INFO - --- Processing Page 23/100: UBOBU_UBO8306198_277667_0023.jpg ---
2025-08-13 08:49:07,281 - ERROR - Critical error on page 23: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:07,281 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:07,281 - INFO - --- Processing Page 24/100: UBOBU_UBO8306198_277667_0024.jpg ---
2025-08-13 08:49:07,624 - ERROR - Critical error on page 24: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:07,646 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:07,651 - INFO - --- Processing Page 25/100: UBOBU_UBO8306198_277667_0025.jpg ---
2025-08-13 08:49:07,880 - ERROR - Critical error on page 25: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:07,880 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:07,880 - INFO - --- Processing Page 26/100: UBOBU_UBO8306198_277667_0026.jpg ---
2025-08-13 08:49:08,086 - ERROR - Critical error on page 26: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:08,090 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:08,092 - INFO - --- Processing Page 27/100: UBOBU_UBO8306198_277667_0027.jpg ---
2025-08-13 08:49:08,296 - ERROR - Critical error on page 27: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:08,300 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:08,302 - INFO - --- Processing Page 28/100: UBOBU_UBO8306198_277667_0028.jpg ---
2025-08-13 08:49:08,514 - ERROR - Critical error on page 28: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:08,518 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:08,518 - INFO - --- Processing Page 29/100: UBOBU_UBO8306198_277667_0029.jpg ---
2025-08-13 08:49:08,746 - ERROR - Critical error on page 29: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:08,746 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:08,746 - INFO - --- Processing Page 30/100: UBOBU_UBO8306198_277667_0030.jpg ---
2025-08-13 08:49:08,946 - ERROR - Critical error on page 30: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:08,965 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:08,965 - INFO - --- Processing Page 31/100: UBOBU_UBO8306198_277667_0031.jpg ---
2025-08-13 08:49:09,114 - ERROR - Critical error on page 31: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,130 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,130 - INFO - --- Processing Page 32/100: UBOBU_UBO8306198_277667_0032.jpg ---
2025-08-13 08:49:09,266 - ERROR - Critical error on page 32: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,284 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,284 - INFO - --- Processing Page 33/100: UBOBU_UBO8306198_277667_0033.jpg ---
2025-08-13 08:49:09,416 - ERROR - Critical error on page 33: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,420 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,421 - INFO - --- Processing Page 34/100: UBOBU_UBO8306198_277667_0034.jpg ---
2025-08-13 08:49:09,565 - ERROR - Critical error on page 34: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,565 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,565 - INFO - --- Processing Page 35/100: UBOBU_UBO8306198_277667_0035.jpg ---
2025-08-13 08:49:09,713 - ERROR - Critical error on page 35: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,713 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,713 - INFO - --- Processing Page 36/100: UBOBU_UBO8306198_277667_0036.jpg ---
2025-08-13 08:49:09,870 - ERROR - Critical error on page 36: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:09,872 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:09,872 - INFO - --- Processing Page 37/100: UBOBU_UBO8306198_277667_0037.jpg ---
2025-08-13 08:49:09,998 - ERROR - Critical error on page 37: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,013 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,013 - INFO - --- Processing Page 38/100: UBOBU_UBO8306198_277667_0038.jpg ---
2025-08-13 08:49:10,148 - ERROR - Critical error on page 38: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,164 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,164 - INFO - --- Processing Page 39/100: UBOBU_UBO8306198_277667_0039.jpg ---
2025-08-13 08:49:10,299 - ERROR - Critical error on page 39: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,299 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,299 - INFO - --- Processing Page 40/100: UBOBU_UBO8306198_277667_0040.jpg ---
2025-08-13 08:49:10,448 - ERROR - Critical error on page 40: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,448 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,448 - INFO - --- Processing Page 41/100: UBOBU_UBO8306198_277667_0041.jpg ---
2025-08-13 08:49:10,613 - ERROR - Critical error on page 41: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,617 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,617 - INFO - --- Processing Page 42/100: UBOBU_UBO8306198_277667_0042.jpg ---
2025-08-13 08:49:10,766 - ERROR - Critical error on page 42: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,766 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,766 - INFO - --- Processing Page 43/100: UBOBU_UBO8306198_277667_0043.jpg ---
2025-08-13 08:49:10,915 - ERROR - Critical error on page 43: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:10,915 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:10,915 - INFO - --- Processing Page 44/100: UBOBU_UBO8306198_277667_0044.jpg ---
2025-08-13 08:49:11,142 - ERROR - Critical error on page 44: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,148 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,148 - INFO - --- Processing Page 45/100: UBOBU_UBO8306198_277667_0045.jpg ---
2025-08-13 08:49:11,265 - ERROR - Critical error on page 45: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,281 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,281 - INFO - --- Processing Page 46/100: UBOBU_UBO8306198_277667_0046.jpg ---
2025-08-13 08:49:11,414 - ERROR - Critical error on page 46: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,414 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,414 - INFO - --- Processing Page 47/100: UBOBU_UBO8306198_277667_0047.jpg ---
2025-08-13 08:49:11,581 - ERROR - Critical error on page 47: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,583 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,583 - INFO - --- Processing Page 48/100: UBOBU_UBO8306198_277667_0048.jpg ---
2025-08-13 08:49:11,715 - ERROR - Critical error on page 48: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,715 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,731 - INFO - --- Processing Page 49/100: UBOBU_UBO8306198_277667_0049.jpg ---
2025-08-13 08:49:11,851 - ERROR - Critical error on page 49: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,851 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,851 - INFO - --- Processing Page 50/100: UBOBU_UBO8306198_277667_0050.jpg ---
2025-08-13 08:49:11,998 - ERROR - Critical error on page 50: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:11,998 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:11,998 - INFO - --- Processing Page 51/100: UBOBU_UBO8306198_277667_0051.jpg ---
2025-08-13 08:49:12,147 - ERROR - Critical error on page 51: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,151 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,151 - INFO - --- Processing Page 52/100: UBOBU_UBO8306198_277667_0052.jpg ---
2025-08-13 08:49:12,299 - ERROR - Critical error on page 52: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,305 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,305 - INFO - --- Processing Page 53/100: UBOBU_UBO8306198_277667_0053.jpg ---
2025-08-13 08:49:12,451 - ERROR - Critical error on page 53: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,451 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,451 - INFO - --- Processing Page 54/100: UBOBU_UBO8306198_277667_0054.jpg ---
2025-08-13 08:49:12,599 - ERROR - Critical error on page 54: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,599 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,599 - INFO - --- Processing Page 55/100: UBOBU_UBO8306198_277667_0055.jpg ---
2025-08-13 08:49:12,765 - ERROR - Critical error on page 55: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,767 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,767 - INFO - --- Processing Page 56/100: UBOBU_UBO8306198_277667_0056.jpg ---
2025-08-13 08:49:12,914 - ERROR - Critical error on page 56: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:12,914 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:12,914 - INFO - --- Processing Page 57/100: UBOBU_UBO8306198_277667_0057.jpg ---
2025-08-13 08:49:13,051 - ERROR - Critical error on page 57: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,051 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,051 - INFO - --- Processing Page 58/100: UBOBU_UBO8306198_277667_0058.jpg ---
2025-08-13 08:49:13,198 - ERROR - Critical error on page 58: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,198 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,198 - INFO - --- Processing Page 59/100: UBOBU_UBO8306198_277667_0059.jpg ---
2025-08-13 08:49:13,348 - ERROR - Critical error on page 59: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,354 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,354 - INFO - --- Processing Page 60/100: UBOBU_UBO8306198_277667_0060.jpg ---
2025-08-13 08:49:13,504 - ERROR - Critical error on page 60: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,504 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,504 - INFO - --- Processing Page 61/100: UBOBU_UBO8306198_277667_0061.jpg ---
2025-08-13 08:49:13,664 - ERROR - Critical error on page 61: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,666 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,666 - INFO - --- Processing Page 62/100: UBOBU_UBO8306198_277667_0062.jpg ---
2025-08-13 08:49:13,888 - ERROR - Critical error on page 62: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:13,888 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:13,888 - INFO - --- Processing Page 63/100: UBOBU_UBO8306198_277667_0063.jpg ---
2025-08-13 08:49:14,015 - ERROR - Critical error on page 63: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,015 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,015 - INFO - --- Processing Page 64/100: UBOBU_UBO8306198_277667_0064.jpg ---
2025-08-13 08:49:14,153 - ERROR - Critical error on page 64: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,165 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,165 - INFO - --- Processing Page 65/100: UBOBU_UBO8306198_277667_0065.jpg ---
2025-08-13 08:49:14,347 - ERROR - Critical error on page 65: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,353 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,353 - INFO - --- Processing Page 66/100: UBOBU_UBO8306198_277667_0066.jpg ---
2025-08-13 08:49:14,498 - ERROR - Critical error on page 66: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,498 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,498 - INFO - --- Processing Page 67/100: UBOBU_UBO8306198_277667_0067.jpg ---
2025-08-13 08:49:14,665 - ERROR - Critical error on page 67: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,665 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,665 - INFO - --- Processing Page 68/100: UBOBU_UBO8306198_277667_0068.jpg ---
2025-08-13 08:49:14,815 - ERROR - Critical error on page 68: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,833 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,833 - INFO - --- Processing Page 69/100: UBOBU_UBO8306198_277667_0069.jpg ---
2025-08-13 08:49:14,964 - ERROR - Critical error on page 69: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:14,980 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:14,980 - INFO - --- Processing Page 70/100: UBOBU_UBO8306198_277667_0070.jpg ---
2025-08-13 08:49:15,114 - ERROR - Critical error on page 70: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,130 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,130 - INFO - --- Processing Page 71/100: UBOBU_UBO8306198_277667_0071.jpg ---
2025-08-13 08:49:15,268 - ERROR - Critical error on page 71: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,272 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,272 - INFO - --- Processing Page 72/100: UBOBU_UBO8306198_277667_0072.jpg ---
2025-08-13 08:49:15,398 - ERROR - Critical error on page 72: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,420 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,420 - INFO - --- Processing Page 73/100: UBOBU_UBO8306198_277667_0073.jpg ---
2025-08-13 08:49:15,564 - ERROR - Critical error on page 73: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,582 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,582 - INFO - --- Processing Page 74/100: UBOBU_UBO8306198_277667_0074.jpg ---
2025-08-13 08:49:15,762 - ERROR - Critical error on page 74: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,762 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,762 - INFO - --- Processing Page 75/100: UBOBU_UBO8306198_277667_0075.jpg ---
2025-08-13 08:49:15,914 - ERROR - Critical error on page 75: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:15,933 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:15,933 - INFO - --- Processing Page 76/100: UBOBU_UBO8306198_277667_0076.jpg ---
2025-08-13 08:49:16,080 - ERROR - Critical error on page 76: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,080 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,080 - INFO - --- Processing Page 77/100: UBOBU_UBO8306198_277667_0077.jpg ---
2025-08-13 08:49:16,232 - ERROR - Critical error on page 77: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,232 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,232 - INFO - --- Processing Page 78/100: UBOBU_UBO8306198_277667_0078.jpg ---
2025-08-13 08:49:16,365 - ERROR - Critical error on page 78: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,365 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,365 - INFO - --- Processing Page 79/100: UBOBU_UBO8306198_277667_0079.jpg ---
2025-08-13 08:49:16,515 - ERROR - Critical error on page 79: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,515 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,515 - INFO - --- Processing Page 80/100: UBOBU_UBO8306198_277667_0080.jpg ---
2025-08-13 08:49:16,663 - ERROR - Critical error on page 80: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,679 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,679 - INFO - --- Processing Page 81/100: UBOBU_UBO8306198_277667_0081.jpg ---
2025-08-13 08:49:16,814 - ERROR - Critical error on page 81: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,832 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,833 - INFO - --- Processing Page 82/100: UBOBU_UBO8306198_277667_0082.jpg ---
2025-08-13 08:49:16,965 - ERROR - Critical error on page 82: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:16,965 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:16,965 - INFO - --- Processing Page 83/100: UBOBU_UBO8306198_277667_0083.jpg ---
2025-08-13 08:49:17,125 - ERROR - Critical error on page 83: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,125 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,125 - INFO - --- Processing Page 84/100: UBOBU_UBO8306198_277667_0084.jpg ---
2025-08-13 08:49:17,265 - ERROR - Critical error on page 84: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,265 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,265 - INFO - --- Processing Page 85/100: UBOBU_UBO8306198_277667_0085.jpg ---
2025-08-13 08:49:17,399 - ERROR - Critical error on page 85: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,411 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,411 - INFO - --- Processing Page 86/100: UBOBU_UBO8306198_277667_0086.jpg ---
2025-08-13 08:49:17,565 - ERROR - Critical error on page 86: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,565 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,565 - INFO - --- Processing Page 87/100: UBOBU_UBO8306198_277667_0087.jpg ---
2025-08-13 08:49:17,730 - ERROR - Critical error on page 87: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,730 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,730 - INFO - --- Processing Page 88/100: UBOBU_UBO8306198_277667_0088.jpg ---
2025-08-13 08:49:17,881 - ERROR - Critical error on page 88: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:17,885 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:17,885 - INFO - --- Processing Page 89/100: UBOBU_UBO8306198_277667_0089.jpg ---
2025-08-13 08:49:18,015 - ERROR - Critical error on page 89: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,015 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,015 - INFO - --- Processing Page 90/100: UBOBU_UBO8306198_277667_0090.jpg ---
2025-08-13 08:49:18,182 - ERROR - Critical error on page 90: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,182 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,182 - INFO - --- Processing Page 91/100: UBOBU_UBO8306198_277667_0091.jpg ---
2025-08-13 08:49:18,393 - ERROR - Critical error on page 91: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,393 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,393 - INFO - --- Processing Page 92/100: UBOBU_UBO8306198_277667_0092.jpg ---
2025-08-13 08:49:18,513 - ERROR - Critical error on page 92: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,513 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,529 - INFO - --- Processing Page 93/100: UBOBU_UBO8306198_277667_0093.jpg ---
2025-08-13 08:49:18,665 - ERROR - Critical error on page 93: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,665 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,665 - INFO - --- Processing Page 94/100: UBOBU_UBO8306198_277667_0094.jpg ---
2025-08-13 08:49:18,815 - ERROR - Critical error on page 94: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,815 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,815 - INFO - --- Processing Page 95/100: UBOBU_UBO8306198_277667_0095.jpg ---
2025-08-13 08:49:18,949 - ERROR - Critical error on page 95: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:18,962 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:18,962 - INFO - --- Processing Page 96/100: UBOBU_UBO8306198_277667_0096.jpg ---
2025-08-13 08:49:19,114 - ERROR - Critical error on page 96: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:19,114 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,114 - INFO - --- Processing Page 97/100: UBOBU_UBO8306198_277667_0097.jpg ---
2025-08-13 08:49:19,265 - ERROR - Critical error on page 97: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:19,265 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,265 - INFO - --- Processing Page 98/100: UBOBU_UBO8306198_277667_0098.jpg ---
2025-08-13 08:49:19,399 - ERROR - Critical error on page 98: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:19,399 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,399 - INFO - --- Processing Page 99/100: UBOBU_UBO8306198_277667_0099.jpg ---
2025-08-13 08:49:19,546 - ERROR - Critical error on page 99: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:19,546 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,546 - INFO - --- Processing Page 100/100: UBOBU_UBO8306198_277667_0100.jpg ---
2025-08-13 08:49:19,696 - ERROR - Critical error on page 100: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 270, in run_batched_multimodal_inference
    raw_classification = call_vision_model(classification_prompt, pil_image, max_new_tokens=args.max_new_tokens_cls) or "Unknown"
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 196, in call_vision_model
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 193, in __call__
    elif not isinstance(text, list) and not isinstance(text[0], str):
                                                       ~~~~^^^
TypeError: 'NoneType' object is not subscriptable
2025-08-13 08:49:19,696 - INFO - Saved partial output to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,696 - INFO - ================================================================================
2025-08-13 08:49:19,696 - INFO - Processing complete.
2025-08-13 08:49:19,696 - INFO - All results saved to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\pixtral.json
2025-08-13 08:49:19,696 - INFO - ================================================================================
2025-08-13 08:53:42,364 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 08:56:05,353 - INFO - Starting fresh run: all images will be processed.
2025-08-13 08:56:05,404 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 08:56:05,447 - INFO - Found 100 images.
2025-08-13 08:56:05,447 - INFO - --- Processing Page 1/100: UBOBU_UBO8306198_277667_0001.jpg ---
2025-08-13 09:08:13,689 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 09:10:47,894 - INFO - Starting fresh run: all images will be processed.
2025-08-13 09:10:47,924 - INFO - Looking for images in: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\imgs
2025-08-13 09:10:47,974 - INFO - Found 100 images.
2025-08-13 09:10:47,974 - INFO - --- Processing Page 1/100: UBOBU_UBO8306198_277667_0001.jpg ---
2025-08-13 09:23:57,481 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 09:26:28,125 - ERROR - Processing error for UBOBU_UBO8306198_277667_0001.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,267 - ERROR - Processing error for UBOBU_UBO8306198_277667_0002.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,366 - ERROR - Processing error for UBOBU_UBO8306198_277667_0003.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,476 - ERROR - Processing error for UBOBU_UBO8306198_277667_0004.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,572 - ERROR - Processing error for UBOBU_UBO8306198_277667_0005.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,714 - ERROR - Processing error for UBOBU_UBO8306198_277667_0006.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:28,848 - ERROR - Processing error for UBOBU_UBO8306198_277667_0007.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,000 - ERROR - Processing error for UBOBU_UBO8306198_277667_0008.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,142 - ERROR - Processing error for UBOBU_UBO8306198_277667_0009.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,354 - ERROR - Processing error for UBOBU_UBO8306198_277667_0010.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,549 - ERROR - Processing error for UBOBU_UBO8306198_277667_0011.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,699 - ERROR - Processing error for UBOBU_UBO8306198_277667_0012.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,849 - ERROR - Processing error for UBOBU_UBO8306198_277667_0013.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:29,995 - ERROR - Processing error for UBOBU_UBO8306198_277667_0014.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,155 - ERROR - Processing error for UBOBU_UBO8306198_277667_0015.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,300 - ERROR - Processing error for UBOBU_UBO8306198_277667_0016.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,460 - ERROR - Processing error for UBOBU_UBO8306198_277667_0017.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,605 - ERROR - Processing error for UBOBU_UBO8306198_277667_0018.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,731 - ERROR - Processing error for UBOBU_UBO8306198_277667_0019.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,865 - ERROR - Processing error for UBOBU_UBO8306198_277667_0020.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:30,980 - ERROR - Processing error for UBOBU_UBO8306198_277667_0021.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,115 - ERROR - Processing error for UBOBU_UBO8306198_277667_0022.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,214 - ERROR - Processing error for UBOBU_UBO8306198_277667_0023.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,348 - ERROR - Processing error for UBOBU_UBO8306198_277667_0024.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,484 - ERROR - Processing error for UBOBU_UBO8306198_277667_0025.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,583 - ERROR - Processing error for UBOBU_UBO8306198_277667_0026.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,781 - ERROR - Processing error for UBOBU_UBO8306198_277667_0027.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:31,883 - ERROR - Processing error for UBOBU_UBO8306198_277667_0028.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,007 - ERROR - Processing error for UBOBU_UBO8306198_277667_0029.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,115 - ERROR - Processing error for UBOBU_UBO8306198_277667_0030.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,234 - ERROR - Processing error for UBOBU_UBO8306198_277667_0031.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,348 - ERROR - Processing error for UBOBU_UBO8306198_277667_0032.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,502 - ERROR - Processing error for UBOBU_UBO8306198_277667_0033.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,654 - ERROR - Processing error for UBOBU_UBO8306198_277667_0034.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,801 - ERROR - Processing error for UBOBU_UBO8306198_277667_0035.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:32,969 - ERROR - Processing error for UBOBU_UBO8306198_277667_0036.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,140 - ERROR - Processing error for UBOBU_UBO8306198_277667_0037.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,250 - ERROR - Processing error for UBOBU_UBO8306198_277667_0038.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,351 - ERROR - Processing error for UBOBU_UBO8306198_277667_0039.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,469 - ERROR - Processing error for UBOBU_UBO8306198_277667_0040.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,583 - ERROR - Processing error for UBOBU_UBO8306198_277667_0041.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,696 - ERROR - Processing error for UBOBU_UBO8306198_277667_0042.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,801 - ERROR - Processing error for UBOBU_UBO8306198_277667_0043.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:33,915 - ERROR - Processing error for UBOBU_UBO8306198_277667_0044.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,016 - ERROR - Processing error for UBOBU_UBO8306198_277667_0045.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,147 - ERROR - Processing error for UBOBU_UBO8306198_277667_0046.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,232 - ERROR - Processing error for UBOBU_UBO8306198_277667_0047.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,342 - ERROR - Processing error for UBOBU_UBO8306198_277667_0048.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,433 - ERROR - Processing error for UBOBU_UBO8306198_277667_0049.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,548 - ERROR - Processing error for UBOBU_UBO8306198_277667_0050.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,650 - ERROR - Processing error for UBOBU_UBO8306198_277667_0051.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,750 - ERROR - Processing error for UBOBU_UBO8306198_277667_0052.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,851 - ERROR - Processing error for UBOBU_UBO8306198_277667_0053.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:34,970 - ERROR - Processing error for UBOBU_UBO8306198_277667_0054.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,081 - ERROR - Processing error for UBOBU_UBO8306198_277667_0055.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,184 - ERROR - Processing error for UBOBU_UBO8306198_277667_0056.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,301 - ERROR - Processing error for UBOBU_UBO8306198_277667_0057.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,415 - ERROR - Processing error for UBOBU_UBO8306198_277667_0058.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,532 - ERROR - Processing error for UBOBU_UBO8306198_277667_0059.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,633 - ERROR - Processing error for UBOBU_UBO8306198_277667_0060.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,736 - ERROR - Processing error for UBOBU_UBO8306198_277667_0061.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,849 - ERROR - Processing error for UBOBU_UBO8306198_277667_0062.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:35,964 - ERROR - Processing error for UBOBU_UBO8306198_277667_0063.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,073 - ERROR - Processing error for UBOBU_UBO8306198_277667_0064.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,215 - ERROR - Processing error for UBOBU_UBO8306198_277667_0065.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,316 - ERROR - Processing error for UBOBU_UBO8306198_277667_0066.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,432 - ERROR - Processing error for UBOBU_UBO8306198_277667_0067.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,559 - ERROR - Processing error for UBOBU_UBO8306198_277667_0068.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,666 - ERROR - Processing error for UBOBU_UBO8306198_277667_0069.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,774 - ERROR - Processing error for UBOBU_UBO8306198_277667_0070.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:36,882 - ERROR - Processing error for UBOBU_UBO8306198_277667_0071.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,001 - ERROR - Processing error for UBOBU_UBO8306198_277667_0072.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,130 - ERROR - Processing error for UBOBU_UBO8306198_277667_0073.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,237 - ERROR - Processing error for UBOBU_UBO8306198_277667_0074.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,347 - ERROR - Processing error for UBOBU_UBO8306198_277667_0075.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,451 - ERROR - Processing error for UBOBU_UBO8306198_277667_0076.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,551 - ERROR - Processing error for UBOBU_UBO8306198_277667_0077.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,681 - ERROR - Processing error for UBOBU_UBO8306198_277667_0078.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,863 - ERROR - Processing error for UBOBU_UBO8306198_277667_0079.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:37,965 - ERROR - Processing error for UBOBU_UBO8306198_277667_0080.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,064 - ERROR - Processing error for UBOBU_UBO8306198_277667_0081.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,164 - ERROR - Processing error for UBOBU_UBO8306198_277667_0082.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,272 - ERROR - Processing error for UBOBU_UBO8306198_277667_0083.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,376 - ERROR - Processing error for UBOBU_UBO8306198_277667_0084.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,482 - ERROR - Processing error for UBOBU_UBO8306198_277667_0085.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,586 - ERROR - Processing error for UBOBU_UBO8306198_277667_0086.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,695 - ERROR - Processing error for UBOBU_UBO8306198_277667_0087.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,801 - ERROR - Processing error for UBOBU_UBO8306198_277667_0088.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:38,903 - ERROR - Processing error for UBOBU_UBO8306198_277667_0089.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,034 - ERROR - Processing error for UBOBU_UBO8306198_277667_0090.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,150 - ERROR - Processing error for UBOBU_UBO8306198_277667_0091.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,252 - ERROR - Processing error for UBOBU_UBO8306198_277667_0092.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,367 - ERROR - Processing error for UBOBU_UBO8306198_277667_0093.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,485 - ERROR - Processing error for UBOBU_UBO8306198_277667_0094.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,603 - ERROR - Processing error for UBOBU_UBO8306198_277667_0095.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,725 - ERROR - Processing error for UBOBU_UBO8306198_277667_0096.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,849 - ERROR - Processing error for UBOBU_UBO8306198_277667_0097.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:39,979 - ERROR - Processing error for UBOBU_UBO8306198_277667_0098.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:40,084 - ERROR - Processing error for UBOBU_UBO8306198_277667_0099.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:40,200 - ERROR - Processing error for UBOBU_UBO8306198_277667_0100.jpg: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 211, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 148, in is_main_page
    inputs = processor(
             ^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\pixtral\processing_pixtral.py", line 226, in __call__
    text_inputs = self.tokenizer(prompt_strings, **output_kwargs["text_kwargs"], return_tensors=None)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2855, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2943, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 3135, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2751, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
2025-08-13 09:26:40,203 - INFO - Processing complete. Found 0 main pages.
2025-08-13 09:26:40,203 - INFO - Results saved to: c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\output\main_pages.json
2025-08-13 09:31:12,496 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 09:34:58,525 - ERROR - Processing error for UBOBU_UBO8306198_277667_0001.jpg: Image features and image tokens do not match: tokens: 0, features 10567680
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 10567680
2025-08-13 09:35:23,779 - ERROR - Processing error for UBOBU_UBO8306198_277667_0002.jpg: Image features and image tokens do not match: tokens: 0, features 10567680
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 10567680
2025-08-13 09:35:49,134 - ERROR - Processing error for UBOBU_UBO8306198_277667_0003.jpg: Image features and image tokens do not match: tokens: 0, features 9830400
Traceback (most recent call last):
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 9830400
2025-08-13 14:29:37,433 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 14:31:13,368 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 14:34:07,229 - ERROR - Processing error for UBOBU_UBO8306198_277667_0001.jpg: Image features and image tokens do not match: tokens: 0, features 10567680
Traceback (most recent call last):
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 10567680
2025-08-13 14:34:18,736 - ERROR - Processing error for UBOBU_UBO8306198_277667_0002.jpg: Image features and image tokens do not match: tokens: 0, features 10567680
Traceback (most recent call last):
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 10567680
2025-08-13 14:34:30,380 - ERROR - Processing error for UBOBU_UBO8306198_277667_0003.jpg: Image features and image tokens do not match: tokens: 0, features 9830400
Traceback (most recent call last):
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 9830400
2025-08-13 14:34:42,426 - ERROR - Processing error for UBOBU_UBO8306198_277667_0004.jpg: Image features and image tokens do not match: tokens: 0, features 9830400
Traceback (most recent call last):
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 215, in process_images
    is_main = is_main_page(pil_image)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\baseline\pixtral_adapt.py", line 160, in is_main_page
    outputs = model.generate(
              ^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 2625, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\generation\utils.py", line 3606, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 455, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\utils\generic.py", line 943, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Lucrezia\Documents\GitHub\TOME-hnp\.venv\Lib\site-packages\transformers\models\llava\modeling_llava.py", line 296, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 9830400
2025-08-13 14:41:31,668 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
2025-08-13 14:45:50,836 - INFO - Loading model: mistral-community/pixtral-12b on cpu with dtype=torch.float32
